{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34bd2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "BASE_LOC = r'/home/or/dev/Intro_to_NLP/task2'\n",
    "POS_DATA_LOC = os.path.join(BASE_LOC, r'data/pos')\n",
    "POS_TRAIN_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-train')\n",
    "POS_DEV_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-dev')\n",
    "#POS_TEST_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-test-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10fb613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wp_to_dict(the_dict, word, pos):\n",
    "    try:\n",
    "        if word in the_dict:\n",
    "            if pos in the_dict[word]:\n",
    "                the_dict[word][pos]['wp_count'] += 1\n",
    "            else:\n",
    "                the_dict[word][pos] = {'wp_count':1, 'right_pos':{}, 'left_pos':{}}\n",
    "\n",
    "        else:\n",
    "            the_dict[word] = {pos: {'wp_count':1, 'right_pos':{}, 'left_pos':{}}}\n",
    "    except:\n",
    "        import pdb; pdb.set_trace();\n",
    "\n",
    "def add_right_pos_to_dict(the_dict, word, pos, right_pos):\n",
    "    try:\n",
    "        #import pdb; pdb.set_trace();\n",
    "        if right_pos in the_dict[word][pos]['right_pos']:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['right_count'] += 1\n",
    "        else:\n",
    "            the_dict[word][pos]['right_pos'][right_pos] = {'right_count':1, 'left_pos':{}}\n",
    "    except:\n",
    "        import pdb; pdb.set_trace();\n",
    "\n",
    "def add_left_pos_to_dict(the_dict, word, pos, left_pos):\n",
    "    if left_pos in the_dict[word][pos]['left_pos']:\n",
    "        the_dict[word][pos]['left_pos'][left_pos]['left_count'] += 1\n",
    "    else:\n",
    "        the_dict[word][pos]['left_pos'][left_pos] = {'left_count':1}\n",
    "        \n",
    "def add_wp_right_pos_left_pos_to_dict(the_dict, word, pos, right_pos, left_pos):\n",
    "    try:    \n",
    "        if left_pos in the_dict[word][pos]['right_pos'][right_pos]['left_pos']:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['left_pos'][left_pos]['left_count'] += 1\n",
    "        else:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['left_pos'][left_pos] = {'left_count':1} \n",
    "    except:\n",
    "        import pdb; pdb.set_trace();        \n",
    "def split_token_pos(token_and_pos, loc):\n",
    "    try:    \n",
    "        token, pos = token_and_pos[loc].rsplit('/',1)\n",
    "    except:\n",
    "        import pdb; pdb.set_trace()\n",
    "    return token, pos\n",
    "\n",
    "\n",
    "\n",
    "def read_file(loc):\n",
    "    file = open(POS_TRAIN_FILE, \"r\")\n",
    "    file_lines = file.readlines()\n",
    "    file.close()\n",
    "    return file_lines\n",
    "\n",
    "def create_dict():\n",
    "    file_lines = read_file(POS_TRAIN_FILE)\n",
    "    words_pos_dict = defaultdict()\n",
    "    for file_line in file_lines:\n",
    "        splitted_line = file_line.split()\n",
    "        len_line = len(splitted_line)\n",
    "        for ii, _ in enumerate(splitted_line):\n",
    "            token, pos = split_token_pos(splitted_line, ii)\n",
    "            add_wp_to_dict(words_pos_dict, token, pos)\n",
    "            if ii  + 1 < len_line:\n",
    "                right_token, right_pos = split_token_pos(splitted_line, ii + 1)\n",
    "                add_right_pos_to_dict(words_pos_dict, token, pos, right_pos)\n",
    "            if ii - 1 <= 0:\n",
    "                left_token, left_pos = split_token_pos(splitted_line, ii - 1)\n",
    "                add_left_pos_to_dict(words_pos_dict, token, pos, left_pos)\n",
    "            if (ii - 1 <= 0) and (ii  + 1 < len_line):\n",
    "                add_wp_right_pos_left_pos_to_dict(words_pos_dict, token, pos, right_pos, left_pos)\n",
    "    return words_pos_dict\n",
    "\n",
    "    file_lines = read_file(POS_TRAIN_FILE)\n",
    "\n",
    "words_pos_dict = create_dict()\n",
    "read_file(loc)\n",
    "#POS_DEV_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67660531",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lines = read_file(POS_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1aa45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dac3d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_location(annotated_location):\n",
    "    len_line = len(annotated_location)\n",
    "    dist_tokens = np.ones(len_line) * -1\n",
    "\n",
    "    for loc in range(len_line):\n",
    "        if annotated_location[loc] == 0:\n",
    "            loc_value = 0\n",
    "            if loc + 1 < len_line:\n",
    "                if annotated_location[loc + 1] == 1:\n",
    "                    loc_value += 2\n",
    "\n",
    "            if loc - 1 >= 0:\n",
    "                if annotated_location[loc -1] == 1:\n",
    "                    loc_value += 1\n",
    "\n",
    "            dist_tokens[loc] = loc_value\n",
    "    print(dist_tokens)\n",
    "    return dist_tokens\n",
    "\n",
    "def split_to_lists(line):\n",
    "    words_list =[]\n",
    "    pos_list = []\n",
    "    \n",
    "    for token_and_pos in line.split():\n",
    "        token, pos = token_and_pos.rsplit('/',1)\n",
    "        words_list.append(token)\n",
    "        pos_list.append(pos)\n",
    "        \n",
    "    return words_list, pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_value(the_dict, indication, right_pos=None,left_pos=None):\n",
    "    gotten_pos_val = NONE_EXIST\n",
    "    if indication == BOTH_POS_IND:\n",
    "        if right_pos in the_dict['right_pos'] and \\\n",
    "        left_pos in the_dict['right_pos'][right_pos]['left_pos']:\n",
    "            gotten_pos_val = the_dict['right_pos'][right_pos]['left_pos'][left_pos]['left_count']\n",
    "        \n",
    "    if indication == RIGHT_POS_IND:\n",
    "        if right_pos in the_dict['right_pos']:\n",
    "            gotten_pos_val = the_dict['right_pos'][right_pos]['right_count']\n",
    "        \n",
    "    if indication == LEFT_POS_IND:\n",
    "        if left_pos in the_dict['left_pos']:\n",
    "            gotten_pos_val = the_dict['left_pos'][left_pos]\n",
    "\n",
    "    if indication == NONE_POS_IND:\n",
    "        gotten_pos_val = the_dict['wp_count']\n",
    "        \n",
    "    return gotten_pos_val\n",
    "    \n",
    "NONE_EXIST = -1\n",
    "NONE_POS_IND = 0\n",
    "LEFT_POS_IND = 1\n",
    "RIGHT_POS_IND = 2\n",
    "BOTH_POS_IND = 3\n",
    "\n",
    "\n",
    "    \n",
    "def test_both(loc, the_dict, words_list, pos_list, indicaton):\n",
    "    best_pos = ''\n",
    "    best_count = NONE_EXIST\n",
    "    \n",
    "    if words_list[loc] in the_dict.keys():\n",
    "        right_pos = pos_list[loc + 1]\n",
    "        left_pos = pos_list[loc - 1]\n",
    "        \n",
    "        for pos, pos_values in the_dict[words_list[loc]].items():\n",
    "            val = match_value(the_dict, indication, right_pos=None,left_pos=None)\n",
    "            if best_count < val:\n",
    "                best_count = val]\n",
    "                best_pos = pos\n",
    "\n",
    "    return best_count, best_pos\n",
    "\n",
    "def test_right(loc, the_dict, words_list, pos_list):\n",
    "    if words_list[loc] in the_dict.keys():\n",
    "        right_pos = pos_list[loc + 1]\n",
    "        if right_pos in words_list[loc]['right_pos']:\n",
    "            gotten_right_pos = words_list[loc]['right_pos'][right_pos]\n",
    "            return gotten_right_pos.keys()[0], gotten_right_pos['right_count']\n",
    "        \n",
    "    return NONE_EXIST, _\n",
    "\n",
    "# def test_both(loc, the_dict, words_list, pos_list):\n",
    "#     if words_list[loc] in the_dict.keys():\n",
    "#         left_pos = pos_list[loc - 1]\n",
    "#         if left_pos in words_list[loc]['left_pos']:\n",
    "#             gotten_left_pos = words_list[loc]['left_pos'][left_pos]\n",
    "#             return gotten_left_pos.keys()[0], gotten_left_pos['left_count']\n",
    "        \n",
    "#     return NONE_EXIST, _\n",
    "\n",
    "# def test_both(loc, the_dict, words_list, pos_list):\n",
    "#     if words_list[loc] in the_dict.keys():\n",
    "#         right_pos = pos_list[loc + 1]\n",
    "#         left_pos = pos_list[loc - 1]\n",
    "#         if right_pos in words_list[loc]['right_pos'] and \\\n",
    "#         left_pos in words_list[loc]['right_pos'][right_pos]['left_pos']:\n",
    "#             left_pos =words_list[loc]['right_pos'][right_pos]['left_pos']['left_pos']\n",
    "#             return left_pos.keys()[0], left_pos['left_count']\n",
    "        \n",
    "#     return NONE_EXIST, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "418c2704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 0])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list, pos_list = split_to_lists(file_lines[0])\n",
    "a =[1,1,0, 0]\n",
    "all_possible_locs = possible_location(a)\n",
    "\n",
    "possible_both_locs = np.where(possible_locs == BOTH_POS_IND)\n",
    "possible_right_locs = np.where(possible_locs == RIGHT_POS_IND)\n",
    "possible_left_locs = np.where(possible_locs == LEFT_POS_IND)\n",
    "possible_none_locs = np.where(possible_locs == NONE_POS_IND)\n",
    "\n",
    "best_both_pos = ''\n",
    "best_both_count = NONE_EXIST\n",
    "best_right_pos = ''\n",
    "best_right_count = NONE_EXIST\n",
    "best_left_pos = ''\n",
    "best_left_count = NONE_EXIST\n",
    "best_none_pos = ''\n",
    "best_none_count = NONE_EXIST\n",
    "\n",
    "# for index in possible_both_locs:\n",
    "#     if possoble_locs[index] == BOTH_POS_IND:\n",
    "#         tested_pos, tested_val = test_both()\n",
    "#         if tested_pos != NONE_EXIST:\n",
    "#             if  best_both_count < tested_val:\n",
    "#                 best_both_count = tested_val\n",
    "#                 best_both_pos = tested_pos\n",
    "                \n",
    "# if best_both_count != NONE_EXIST:\n",
    "#     return best_both_pos\n",
    "\n",
    "best_count, best_pos = get_pos(possible_locs, test_both, BOTH_POS_IND, the_dict, words_list, pos_list)\n",
    "if best_count != NONE_EXIST\n",
    "    return best_pos\n",
    "best_count, best_pos = get_pos(possible_locs, test_func, RIGHT_POS_IND, the_dict, words_list, pos_list)\n",
    "if best_count != NONE_EXIST:\n",
    "    return best_pos\n",
    "best_count, best_pos = get_pos(possible_locs, test_func, LEFT_POS_IND, the_dict, words_list, pos_list)\n",
    "if best_count != NONE_EXIST:\n",
    "    return best_pos\n",
    "best_count, best_pos = get_pos(possible_locs, test_func, NONE_POS_IND, the_dict, words_list, pos_list)\n",
    "return best_pos\n",
    "\n",
    "def get_pos(all_possible_locs, test_func, indication, the_dict, words_list, pos_list):\n",
    "    possible_both_locs = np.where(all_possible_locs == indication)\n",
    "\n",
    "    best_pos = ''\n",
    "    best_count = NONE_EXIST\n",
    "\n",
    "    for loc in possible_locs:\n",
    "        tested_pos, tested_val = test_func(loc, the_dict, words_list, pos_list)\n",
    "        if tested_pos != NONE_EXIST:\n",
    "            if  best_count < tested_val:\n",
    "                best_count = tested_val\n",
    "                best_pos = tested_pos\n",
    "\n",
    "    return best_count, best_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "49115b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_to_anottate(annotated_location):\n",
    "    len_line = len(annotated_location)\n",
    "    dist_tokens = np.ones(len_line) * -1\n",
    "\n",
    "    for loc in range(len_line):\n",
    "        if annotated_location[loc] == 0:\n",
    "            loc_value = 0\n",
    "            if loc + 1 < len_line:\n",
    "                if annotated_location[loc + 1] == 1:\n",
    "                    loc_value += 2\n",
    "\n",
    "            if loc - 1 >= 0:\n",
    "                if annotated_location[loc -1] == 1:\n",
    "                    loc_value += 1\n",
    "\n",
    "            if loc_value == 3:\n",
    "                return loc, loc_value\n",
    "\n",
    "            dist_tokens[loc] = loc_value\n",
    "\n",
    "    index = np.argmax(dist_tokens)\n",
    "    val_max = dist_tokens[index]\n",
    "    return index, val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9fa9ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "70dfaf10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NONE_EXIST = -1\n",
    "NONE_POS_IND = 0\n",
    "LEFT_POS_IND = 1\n",
    "RIGHT_POS_IND = 2\n",
    "BOTH_POS_IND = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e66eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kind == NONE_POS_IND:\n",
    "    if token in words_pos_dict.keys():\n",
    "        max_count = -np.inf\n",
    "        selected_pos = ''\n",
    "        for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "            wp_count = pos_values['wp_count']\n",
    "            if wp_count > max_count:\n",
    "                max_count = wp_count \n",
    "                selected_pos = tested_pos\n",
    "    else:\n",
    "        raise token\n",
    "        \n",
    "if kind == LEFT_POS_IND:\n",
    "    if token in words_pos_dict.keys():\n",
    "    max_count = -np.inf\n",
    "    selected_pos = ''\n",
    "    for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "        for\n",
    "        wp_count = pos_values['wp_count']\n",
    "        if wp_count > max_count:\n",
    "            max_count = wp_count \n",
    "            selected_pos = tested_pos\n",
    "    else:\n",
    "        raise token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b239c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a2ef319",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_line = file_lines[0].split()\n",
    "len_line = len(splitted_line)\n",
    "annotated_location = np.zeros(len_line)\n",
    "annotated_token = [''] * len_line\n",
    "words_list =[]\n",
    "pos_lost = []\n",
    "while not all(annotated_location):\n",
    "    loc_to_annotate, kind = location_to_anottate(annotated_location)\n",
    "    token, pos = split_token_pos(splitted_line, ii)\n",
    "    \n",
    "for ii, _ in enumerate(splitted_line):\n",
    "    token, pos = split_token_pos(splitted_line, ii)\n",
    "    #print(words_pos_dict[token])\n",
    "    if token in words_pos_dict.keys():\n",
    "        max_count = -np.inf\n",
    "        selected_pos = ''\n",
    "        for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "            wp_count = pos_values['wp_count']\n",
    "            if wp_count > max_count:\n",
    "                max_count = wp_count \n",
    "                selected_pos = tested_pos\n",
    "    else:\n",
    "        raise token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3ae91f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN 1735\n",
      "RB 1\n",
      "NNP 3\n",
      "RBR 1\n",
      "DT 3142\n",
      ", 1\n",
      "NNP 317\n",
      "NN 1\n",
      "CD 100\n",
      "NN 36\n",
      "VB 21\n",
      "VBP 1\n",
      "IN 22925\n",
      "RP 2\n",
      "RB 2\n",
      "`` 6967\n",
      "DT 6795\n",
      "NNP 37\n",
      "VB 1\n",
      "NN 3\n",
      "'' 6787\n",
      "IN 4361\n",
      "RP 1\n",
      "NNP 197\n",
      "POS 8079\n",
      "VBZ 1222\n",
      "PRP 8\n",
      "NNP 1\n",
      "NNS 1\n",
      "NNP 7\n",
      "NNP 5\n",
      "( 1153\n",
      "`` 6967\n",
      "VBN 1\n",
      "NNS 1\n",
      "VBP 1\n",
      "VB 8\n",
      "DT 41098\n",
      "VBP 1\n",
      "NNP 5\n",
      "NN 1\n",
      "JJ 2\n",
      "NN 1\n",
      "NNP 2\n",
      "IN 14957\n",
      "RP 173\n",
      "RB 53\n",
      "FW 2\n",
      "RBR 1\n",
      "NNP 1\n",
      "NNP 132\n",
      "NN 7\n",
      ", 48723\n",
      "'' 6787\n",
      "NN 2\n",
      "NNP 1\n",
      "CC 1033\n",
      "SYM 1\n",
      "NNS 2\n",
      "NNP 4\n",
      "NNPS 2\n",
      ") 1160\n",
      ", 48723\n",
      "DT 41098\n",
      "VBP 1\n",
      "NNP 5\n",
      "NN 1\n",
      "JJ 2\n",
      "NN 125\n",
      "IN 22925\n",
      "RP 2\n",
      "RB 2\n",
      "NNP 4\n",
      ", 48723\n",
      "VBN 23\n",
      "VBD 30\n",
      "IN 4483\n",
      "RP 10\n",
      "RB 2\n",
      "NNP 7\n",
      "NNP 1\n",
      ", 48723\n",
      "VBD 3903\n",
      "RB 6\n",
      "VBN 17\n",
      "VBD 52\n",
      "IN 9282\n",
      "TO 12916\n",
      "NNP 2\n",
      "NNP 3\n",
      ". 39020\n"
     ]
    }
   ],
   "source": [
    "splitted_line = file_lines[0].split()\n",
    "len_line = len(splitted_line)\n",
    "for ii, _ in enumerate(splitted_line):\n",
    "    token, pos = split_token_pos(splitted_line, ii)\n",
    "    #print(words_pos_dict[token])\n",
    "    if token in words_pos_dict.keys():\n",
    "        max_count = -np.inf\n",
    "        selected_pos = ''\n",
    "        for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "            wp_count = pos_values['wp_count']\n",
    "            if wp_count > max_count:\n",
    "                max_count = wp_count \n",
    "                selected_pos = tested_pos\n",
    "    else:\n",
    "        raise token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "631064f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b237bf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['.'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if token in words_pos_dict.key():\n",
    "    max_count = 0 \n",
    "    for pos_dict in words_pos_dict[word]:\n",
    "        print(pos_dict,pos_dict.keys())\n",
    "        wp_count = pos_dict['wp_count']\n",
    "        if wp_count > max_count:\n",
    "            max_count = wp_count \n",
    "else:\n",
    "    raise token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for words_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def saving(file_loc, dest_loc):\n",
    "    file = open(file_loc, \"r\")\n",
    "    sentence = []\n",
    "    sentences = []\n",
    "    file_chunk = file.readlines(CHUNCK)\n",
    "    \n",
    "    tic = time()\n",
    "    while file_chunk:\n",
    "        for line in file_chunk:\n",
    "            if line == '\\n':\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            else:\n",
    "                splitted_line = line.split()\n",
    "                sentence.append((splitted_line[2], splitted_line[3]))\n",
    "        file_chunk = file.readlines(CHUNCK)\n",
    "        \n",
    "    if len(sentence):\n",
    "        sentences.append(sentence)\n",
    "    file.close()\n",
    "    toc = time()\n",
    "    sentence_len = len(sentences)\n",
    "    \n",
    "    print('File reading time(minutes): ', round((toc- tic)/60, 2),'Sentences: ', sentence_len)\n",
    "    \n",
    "    tic = time()\n",
    "    with open(dest_loc, \"wb\" ) as f:\n",
    "        pickle.dump(sentences, f)\n",
    "    toc = time()\n",
    "    print('Saving time(minutes): ', round((toc- tic)/60, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
