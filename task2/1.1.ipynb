{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34bd2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "BASE_LOC = r'/home/or/dev/Intro_to_NLP/task2'\n",
    "POS_DATA_LOC = os.path.join(BASE_LOC, r'data/pos')\n",
    "POS_TRAIN_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-train')\n",
    "POS_DEV_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-dev')\n",
    "#POS_TEST_FILE = os.path.join(POS_DATA_LOC, 'ass1-tagger-test-input')\n",
    "\n",
    "NONE_EXIST = -1\n",
    "NONE_POS_IND = 0\n",
    "LEFT_POS_IND = 1\n",
    "RIGHT_POS_IND = 2\n",
    "BOTH_POS_IND = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81febe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wp_to_dict(the_dict, word, pos):\n",
    "    try:\n",
    "        if word in the_dict:\n",
    "            if pos in the_dict[word]:\n",
    "                the_dict[word][pos]['wp_count'] += 1\n",
    "            else:\n",
    "                the_dict[word][pos] = {'wp_count':1, 'right_pos':{}, 'left_pos':{}}\n",
    "\n",
    "        else:\n",
    "            the_dict[word] = {pos: {'wp_count':1, 'right_pos':{}, 'left_pos':{}}}\n",
    "    except:\n",
    "        import pdb; pdb.set_trace();\n",
    "\n",
    "def add_right_pos_to_dict(the_dict, word, pos, right_pos):\n",
    "    try:\n",
    "        #import pdb; pdb.set_trace();\n",
    "        if right_pos in the_dict[word][pos]['right_pos']:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['right_count'] += 1\n",
    "        else:\n",
    "            the_dict[word][pos]['right_pos'][right_pos] = {'right_count':1, 'left_pos':{}}\n",
    "    except:\n",
    "        import pdb; pdb.set_trace();\n",
    "\n",
    "def add_left_pos_to_dict(the_dict, word, pos, left_pos):\n",
    "    if left_pos in the_dict[word][pos]['left_pos']:\n",
    "        the_dict[word][pos]['left_pos'][left_pos]['left_count'] += 1\n",
    "    else:\n",
    "        the_dict[word][pos]['left_pos'][left_pos] = {'left_count':1}\n",
    "        \n",
    "def add_wp_right_pos_left_pos_to_dict(the_dict, word, pos, right_pos, left_pos):\n",
    "    try:    \n",
    "        if left_pos in the_dict[word][pos]['right_pos'][right_pos]['left_pos']:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['left_pos'][left_pos]['left_count'] += 1\n",
    "        else:\n",
    "            the_dict[word][pos]['right_pos'][right_pos]['left_pos'][left_pos] = {'left_count':1} \n",
    "    except:\n",
    "        import pdb; pdb.set_trace();        \n",
    "def split_token_pos(token_and_pos, loc):\n",
    "    try:    \n",
    "        token, pos = token_and_pos[loc].rsplit('/',1)\n",
    "    except:\n",
    "        import pdb; pdb.set_trace()\n",
    "    return token, pos\n",
    "\n",
    "\n",
    "\n",
    "def read_file(loc):\n",
    "    file = open(POS_TRAIN_FILE, \"r\")\n",
    "    file_lines = file.readlines()\n",
    "    file.close()\n",
    "    return file_lines\n",
    "\n",
    "def create_dict():\n",
    "    file_lines = read_file(POS_TRAIN_FILE)\n",
    "    words_pos_dict = defaultdict()\n",
    "    for file_line in file_lines:\n",
    "        splitted_line = file_line.split()\n",
    "        len_line = len(splitted_line)\n",
    "        for ii, _ in enumerate(splitted_line):\n",
    "            token, pos = split_token_pos(splitted_line, ii)\n",
    "            add_wp_to_dict(words_pos_dict, token, pos)\n",
    "            if ii  + 1 < len_line:\n",
    "                right_token, right_pos = split_token_pos(splitted_line, ii + 1)\n",
    "                add_right_pos_to_dict(words_pos_dict, token, pos, right_pos)\n",
    "            if ii - 1 <= 0:\n",
    "                left_token, left_pos = split_token_pos(splitted_line, ii - 1)\n",
    "                add_left_pos_to_dict(words_pos_dict, token, pos, left_pos)\n",
    "            if (ii - 1 <= 0) and (ii  + 1 < len_line):\n",
    "                add_wp_right_pos_left_pos_to_dict(words_pos_dict, token, pos, right_pos, left_pos)\n",
    "    return words_pos_dict\n",
    "\n",
    "    file_lines = read_file(POS_TRAIN_FILE)\n",
    "\n",
    "words_pos_dict = create_dict()\n",
    "read_file(loc)\n",
    "#POS_DEV_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a744b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lines = read_file(POS_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4cbdd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(BASE_LOC, r'dict_temp.json'), 'w') as fp:\n",
    "    json.dump(words_pos_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930631f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "611bfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_location(annotated_location):\n",
    "    len_line = len(annotated_location)\n",
    "    dist_tokens = np.ones(len_line) * -1\n",
    "\n",
    "    for loc in range(len_line):\n",
    "        if annotated_location[loc] == 0:\n",
    "            loc_value = 0\n",
    "            if loc + 1 < len_line:\n",
    "                if annotated_location[loc + 1] == 1:\n",
    "                    loc_value += 2\n",
    "\n",
    "            if loc - 1 >= 0:\n",
    "                if annotated_location[loc -1] == 1:\n",
    "                    loc_value += 1\n",
    "\n",
    "            dist_tokens[loc] = loc_value\n",
    "    print(dist_tokens)\n",
    "    return dist_tokens\n",
    "\n",
    "def split_to_lists(line):\n",
    "    words_list =[]\n",
    "    pos_list = []\n",
    "    \n",
    "    for token_and_pos in line.split():\n",
    "        token, pos = token_and_pos.rsplit('/',1)\n",
    "        words_list.append(token)\n",
    "        pos_list.append(pos)\n",
    "        \n",
    "    return words_list, pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2cdcd8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_value(the_dict, indication, right_pos, left_pos):\n",
    "    gotten_pos_val = NONE_EXIST\n",
    "    if indication == BOTH_POS_IND:\n",
    "        if right_pos in the_dict['right_pos'] and \\\n",
    "        left_pos in the_dict['right_pos'][right_pos]['left_pos']:\n",
    "            gotten_pos_val = the_dict['right_pos'][right_pos]['left_pos'][left_pos]['left_count']\n",
    "        \n",
    "    if indication == RIGHT_POS_IND:\n",
    "        if right_pos in the_dict['right_pos']:\n",
    "            gotten_pos_val = the_dict['right_pos'][right_pos]['right_count']\n",
    "        \n",
    "    if indication == LEFT_POS_IND:\n",
    "        if left_pos in the_dict['left_pos']:\n",
    "            gotten_pos_val = the_dict['left_pos'][left_pos]\n",
    "\n",
    "    if indication == NONE_POS_IND:\n",
    "        gotten_pos_val = the_dict['wp_count']\n",
    "        \n",
    "    return gotten_pos_val\n",
    "\n",
    "def best_pos_in_loc(loc, the_dict, words_list, pos_list, indicaton):\n",
    "    best_pos = ''\n",
    "    best_count = NONE_EXIST\n",
    "    \n",
    "    if words_list[loc] in the_dict.keys():\n",
    "        right_pos = pos_list[loc + 1]\n",
    "        left_pos = pos_list[loc - 1]\n",
    "        \n",
    "        for pos, pos_values in the_dict[words_list[loc]].items():\n",
    "            val = match_value(the_dict, indication, right_pos,left_pos)\n",
    "            if best_count < val:\n",
    "                best_count = val\n",
    "                best_pos = pos\n",
    "\n",
    "    return best_count, best_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "97045a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pos(file_lines, annotated_location, words_list, pos_list, the_dict):\n",
    "    possible_locs = possible_location(annotated_location)\n",
    "\n",
    "\n",
    "    best_count, best_pos, loc = get_pos_for_indication(possible_locs, BOTH_POS_IND, the_dict, words_list, pos_list)\n",
    "    if best_count != NONE_EXIST:\n",
    "        return best_pos, loc\n",
    "    best_count, best_pos, loc = get_pos_for_indication(possible_locs, RIGHT_POS_IND, the_dict, words_list, pos_list)\n",
    "    if best_count != NONE_EXIST:\n",
    "        return best_pos, loc\n",
    "    best_count, best_pos, loc = get_pos_for_indication(possible_locs, LEFT_POS_IND, the_dict, words_list, pos_list)\n",
    "    if best_count != NONE_EXIST:\n",
    "        return best_pos, loc\n",
    "    best_count, best_pos, loc = get_pos_for_indication(possible_locs, NONE_POS_IND, the_dict, words_list, pos_list)\n",
    "    return best_pos, loc\n",
    "\n",
    "def get_pos_for_indication(all_possible_locs, indication, the_dict, words_list, pos_list):\n",
    "    specific_possible_locs = np.where(all_possible_locs == indication)\n",
    "\n",
    "    best_pos = ''\n",
    "    best_count = NONE_EXIST\n",
    "\n",
    "    for loc in specific_possible_locs:\n",
    "        tested_pos, tested_val = best_pos_in_loc(loc, the_dict, words_list, pos_list, indication)\n",
    "        if tested_pos != NONE_EXIST:\n",
    "            if  best_count < tested_val:\n",
    "                best_count = tested_val\n",
    "                best_pos = tested_pos\n",
    "\n",
    "    return best_count, best_pos, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8001a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26219/3760760712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_to_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_pos_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mannotated_location\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mannotated_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26219/917691989.py\u001b[0m in \u001b[0;36mget_best_pos\u001b[0;34m(file_lines, annotated_location, words_list, pos_list, the_dict)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbest_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pos_for_indication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOTH_POS_IND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_count\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNONE_EXIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26219/917691989.py\u001b[0m in \u001b[0;36mget_pos_for_indication\u001b[0;34m(all_possible_locs, indication, the_dict, words_list, pos_list)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecific_possible_locs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtested_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtested_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_pos_in_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindication\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtested_pos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNONE_EXIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m  \u001b[0mbest_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtested_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26219/3329122170.py\u001b[0m in \u001b[0;36mbest_pos_in_loc\u001b[0;34m(loc, the_dict, words_list, pos_list, indicaton)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbest_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNONE_EXIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mright_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mleft_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "splitted_line = file_lines[0].split()\n",
    "len_line = len(splitted_line)\n",
    "annotated_location = np.zeros(len_line)\n",
    "annotated_token = [''] * len_line\n",
    "words_list = []\n",
    "pos_lost = []\n",
    "\n",
    "words_list, label_pos = split_to_lists(file_lines[0])\n",
    "while not all(annotated_location):\n",
    "    best_pos, loc = get_best_pos(file_lines, annotated_location, words_list, annotated_token, words_pos_dict)\n",
    "    annotated_location[loc] = 1\n",
    "    annotated_token[loc] = best_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e1f2a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def location_to_anottate(annotated_location):\n",
    "#     len_line = len(annotated_location)\n",
    "#     dist_tokens = np.ones(len_line) * -1\n",
    "\n",
    "#     for loc in range(len_line):\n",
    "#         if annotated_location[loc] == 0:\n",
    "#             loc_value = 0\n",
    "#             if loc + 1 < len_line:\n",
    "#                 if annotated_location[loc + 1] == 1:\n",
    "#                     loc_value += 2\n",
    "\n",
    "#             if loc - 1 >= 0:\n",
    "#                 if annotated_location[loc -1] == 1:\n",
    "#                     loc_value += 1\n",
    "\n",
    "#             if loc_value == 3:\n",
    "#                 return loc, loc_value\n",
    "\n",
    "#             dist_tokens[loc] = loc_value\n",
    "\n",
    "#     index = np.argmax(dist_tokens)\n",
    "#     val_max = dist_tokens[index]\n",
    "#     return index, val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92deaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if kind == NONE_POS_IND:\n",
    "#     if token in words_pos_dict.keys():\n",
    "#         max_count = -np.inf\n",
    "#         selected_pos = ''\n",
    "#         for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "#             wp_count = pos_values['wp_count']\n",
    "#             if wp_count > max_count:\n",
    "#                 max_count = wp_count \n",
    "#                 selected_pos = tested_pos\n",
    "#     else:\n",
    "#         raise token\n",
    "        \n",
    "# if kind == LEFT_POS_IND:\n",
    "#     if token in words_pos_dict.keys():\n",
    "#     max_count = -np.inf\n",
    "#     selected_pos = ''\n",
    "#     for tested_pos, pos_values in words_pos_dict[token].items():\n",
    "#         for\n",
    "#         wp_count = pos_values['wp_count']\n",
    "#         if wp_count > max_count:\n",
    "#             max_count = wp_count \n",
    "#             selected_pos = tested_pos\n",
    "#     else:\n",
    "#         raise token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
