{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f918298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/.virtualenvs/biu_task2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|███████████████████████████| 501M/501M [02:12<00:00, 3.79MB/s]\n",
      "Downloading: 100%|████████████████████████████| 899k/899k [00:01<00:00, 847kB/s]\n",
      "Downloading: 100%|████████████████████████████| 456k/456k [00:00<00:00, 535kB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.36M/1.36M [00:01<00:00, 1.21MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3306529223918915,\n",
       "  'token': 2943,\n",
       "  'token_str': ' male',\n",
       "  'sequence': \"Hello I'm a male model.\"},\n",
       " {'score': 0.04655393213033676,\n",
       "  'token': 2182,\n",
       "  'token_str': ' female',\n",
       "  'sequence': \"Hello I'm a female model.\"},\n",
       " {'score': 0.04233003035187721,\n",
       "  'token': 2038,\n",
       "  'token_str': ' professional',\n",
       "  'sequence': \"Hello I'm a professional model.\"},\n",
       " {'score': 0.03721676394343376,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello I'm a fashion model.\"},\n",
       " {'score': 0.03253666311502457,\n",
       "  'token': 1083,\n",
       "  'token_str': ' Russian',\n",
       "  'sequence': \"Hello I'm a Russian model.\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='roberta-base')\n",
    "unmasker(\"Hello I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef3b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am so <mask>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34dc6cbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> : 0\n",
      "I : 100\n",
      " am : 524\n",
      " so : 98\n",
      "<mask> : 50264\n",
      "</s> : 2\n",
      "\n",
      "------------------------\n",
      "\n",
      "5 most similar to 'am':\n",
      ">>> I am so  am,    (probability:0.9998922348022461)\n",
      ">>> I am so  is,    (probability:3.9378628571284935e-05)\n",
      ">>> I am so 'm,    (probability:2.9937518775113858e-05)\n",
      ">>> I am so  was,    (probability:8.688964953762479e-06)\n",
      ">>> I am so  feel,    (probability:8.550764505343977e-06)\n",
      "\n",
      "------------------------\n",
      "5 most similar to '<mask>':\n",
      ">>> I am so  sorry,    (probability:0.3083705008029938)\n",
      ">>> I am so  proud,    (probability:0.0649036392569542)\n",
      ">>> I am so  grateful,    (probability:0.05806168541312218)\n",
      ">>> I am so  happy,    (probability:0.04478686675429344)\n",
      ">>> I am so  blessed,    (probability:0.032352522015571594)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "model_checkpoint = 'roberta-base'\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "for code in inputs['input_ids'][0]:\n",
    "    print(f\"{ tokenizer.decode(code)} : {code}\")\n",
    "    \n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    \n",
    "am_loc = 2\n",
    "mask_loc = 4\n",
    "def k_most_similar(logits, index):\n",
    "    mask_token_logits = logits[0, index, :]\n",
    "    # Pick the [MASK] candidates with the highest logits\n",
    "    probabilities = F.softmax(mask_token_logits,dim=0)\n",
    "    top_5_tokens = np.argsort(-probabilities)[:5].tolist()\n",
    "    \n",
    "    for token in top_5_tokens:\n",
    "        print(f\">>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))},    (probability:{probabilities[token]})\")\n",
    "\n",
    "print('\\n------------------------\\n')\n",
    "print(\"5 most similar to 'am':\") \n",
    "k_most_similar(logits, am_loc)\n",
    "print('\\n------------------------')\n",
    "print(\"5 most similar to '<mask>':\") \n",
    "k_most_similar(logits, mask_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67877b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.0206e-14, 1.6637e-15, 5.3132e-09,  ..., 6.7266e-14, 3.4216e-14,\n",
       "        2.4555e-12])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(mask_token_logits,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98f9a4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8396, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af0d1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_logits = logits[0, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f32ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50265])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a764ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
