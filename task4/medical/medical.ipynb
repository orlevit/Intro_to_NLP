{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2072fc6a",
   "metadata": {},
   "source": [
    "# Healthcare Data Entities Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1694ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing and importing relevant libraries\n",
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "from time import time\n",
    "from spacy.tokenizer import Tokenizer\n",
    "SENT_RANGE = 10 # Range of word to consider as features\n",
    "\n",
    "# load the model\n",
    "model = spacy.load(\"en_core_web_sm\")\n",
    "model.tokenizer = Tokenizer(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dead2f",
   "metadata": {},
   "source": [
    "# Dataset prepration and overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb9f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples:  830  Number of negative samples:  830\n"
     ]
    }
   ],
   "source": [
    "none_all = []\n",
    "medical_sample = []\n",
    "with open('data.txt', 'r') as data_file:\n",
    "    for line in data_file:\n",
    "        if line.endswith('||NONE\\n'):\n",
    "            none_all.append(line.replace('||NONE\\n', ''))\n",
    "        elif line.endswith('||TREAT_FOR_DIS\\n'):\n",
    "            medical_sample.append(line.replace('||TREAT_FOR_DIS\\n', ''))\n",
    "\n",
    "none_sample = none_all[:len(medical_sample)]\n",
    "print('Number of positive samples: ', len(none_sample), ' Number of negative samples: ',len(medical_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4973c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len  = int(len(medical_sample) * 0.7)\n",
    "train1, test1 = medical_sample[:train_len], medical_sample[train_len:] \n",
    "train2, test2 = none_sample[:train_len], none_sample[train_len:] \n",
    "train = train1 + train2\n",
    "test = test1 + test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b7f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentences(org_sentences):\n",
    "    sentences_formatted = []\n",
    "    annotations = []\n",
    "    single_annot = 'O'\n",
    "    for sentence in org_sentences:\n",
    "        sentence_formatted = ''\n",
    "        annotation = ''\n",
    "        for word in sentence.split():\n",
    "            if word == '<DIS>':\n",
    "                single_annot = 'D'\n",
    "\n",
    "            elif word == '</DIS>':\n",
    "                single_annot = 'O'\n",
    "\n",
    "            elif word == '<TREAT>':\n",
    "                single_annot = 'T'\n",
    "\n",
    "            elif word == '</TREAT>':\n",
    "                single_annot = 'O'\n",
    "            else:\n",
    "                sentence_formatted += word + ' '\n",
    "                annotation += single_annot + ' '\n",
    "\n",
    "        sentences_formatted.append(sentence_formatted.strip())\n",
    "        annotations.append(annotation.strip())\n",
    "        \n",
    "    return sentences_formatted, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bc730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels = format_sentences(train)\n",
    "test_sentences, test_labels = format_sentences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ca49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Datasets statistics: --------------------\n",
      "\n",
      "'T' - Treatment\n",
      "'D' - Disease\n",
      "'O' - Other\n",
      "------------- Train dataset -------------\n",
      "Train annotations counts\n",
      "O                           25099\n",
      "T                            2159\n",
      "D                            1956\n",
      "dtype: int64\n",
      "NER tokens('D'/'T'): 0.141%, 'O' tokens: 0.859%\n",
      "Number of sentences: 1162\n",
      "\n",
      "------------- Test dataset -------------\n",
      "Test annotations counts\n",
      "O                          8336\n",
      "T                           777\n",
      "D                           683\n",
      "dtype: int64\n",
      "NER tokens('D'/'T'): 0.149%, 'O' tokens: 0.851%\n",
      "Number of sentences: 498\n"
     ]
    }
   ],
   "source": [
    "train_count_total = [sent_lbl for sentence_labels in train_labels for sent_lbl in sentence_labels if sent_lbl != ' ']\n",
    "train_count_o = [sent_lbl for sentence_labels in train_labels for sent_lbl in sentence_labels if sent_lbl != ' ' and sent_lbl == 'O']\n",
    "O_percent = round(len(train_count_o)/len(train_count_total),3)\n",
    "ner_percent = 1 - O_percent\n",
    "df = pd.DataFrame()\n",
    "df['Train annotations counts'] = train_count_total\n",
    "print('-------------------- Datasets statistics: --------------------\\n')\n",
    "print(\"'T' - Treatment\")\n",
    "print(\"'D' - Disease\")\n",
    "print(\"'O' - Other\")\n",
    "print('------------- Train dataset -------------')\n",
    "print(df.value_counts())\n",
    "print(\"NER tokens('D'/'T'): {}%, 'O' tokens: {}%\".format(round(ner_percent,4), O_percent))\n",
    "print(\"Number of sentences: {}\".format(len(train_sentences)))\n",
    "\n",
    "\n",
    "test_count_total = [sent_lbl for sentence_labels in test_labels for sent_lbl in sentence_labels if sent_lbl != ' ']\n",
    "test_count_o = [sent_lbl for sentence_labels in test_labels for sent_lbl in sentence_labels if sent_lbl != ' ' and sent_lbl == 'O']\n",
    "O_percent = round(len(test_count_o)/len(test_count_total),3)\n",
    "ner_percent = 1 - O_percent\n",
    "df = pd.DataFrame()\n",
    "df['Test annotations counts'] = test_count_total\n",
    "\n",
    "print('\\n------------- Test dataset -------------')\n",
    "print(df.value_counts())\n",
    "print(\"NER tokens('D'/'T'): {}%, 'O' tokens: {}%\".format(round(ner_percent,4), O_percent))\n",
    "print(\"Number of sentences: {}\".format(len(test_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46c3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test annotations\n",
      "O                   8336\n",
      "T                    777\n",
      "D                    683\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'T' - Treatment\n",
    "# 'D' - Disease\n",
    "# 'O' - Other\n",
    "test_count_total = [sent_lbl for sentence_labels in test_labels for sent_lbl in sentence_labels if sent_lbl != ' ']\n",
    "df = pd.DataFrame()\n",
    "df['Test annotations'] = test_count_total\n",
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7d75f",
   "metadata": {},
   "source": [
    "# Defining features for CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81bc15",
   "metadata": {},
   "source": [
    "## Select one out of two options:\n",
    "1) 10 range word feature from left and right\n",
    "\n",
    "2) Previous and next word features\n",
    "\n",
    "3) Previous word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee17163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Range of \"SENT_RANGE\" range of features\n",
    "def getFeaturesForOneWord(cur_loc, sentence):\n",
    "    end_loc = len(sentence) - 1\n",
    "\n",
    "    # Obtaining features for words\n",
    "    features = []\n",
    "    left_range = max(0, cur_loc - SENT_RANGE)\n",
    "    right_range = min(end_loc, cur_loc + 10)\n",
    "\n",
    "    for i_loc in range(left_range, right_range):\n",
    "        word = sentence[i_loc]\n",
    "        i = i_loc - cur_loc\n",
    "        features.extend([\n",
    "        f'word{i}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "        f'word{i}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "        f'word{i}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "        f'word{i}.dep=' + word.dep_,                                             # dependency dependent\n",
    "        f'word{i}.head=' + word.head.orth_,                                      # dependency head\n",
    "        f'word{i}.isupper={word.orth_.isupper()}',                            # is the word in all uppercase\n",
    "        f'word{i}.isdigit={word.orth_.isdigit()}',                            # is the word a number\n",
    "        f'word{i}.startsWithCapital={word.orth_[0].isupper()}'])               # is the word starting with a capital letter\n",
    "        \n",
    "    if(cur_loc == 0):\n",
    "        features.append('BEG')                                                # feature to track begin of sentence \n",
    " \n",
    "    elif(cur_loc == end_loc - 1):\n",
    "        features.append('END')                                                # feature to track end of sentence\n",
    " \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c45bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Previous, current and next word features\n",
    "def getFeaturesForOneWord(cur_loc, sentence):\n",
    "    end_loc = len(sentence) - 1\n",
    "    # Obtaining features for current word\n",
    "    word = sentence[cur_loc]\n",
    " \n",
    "    features = [\n",
    "    f'word{0}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "    f'word{0}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "    f'word{0}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "    f'word{0}.dep=' + word.dep_,                                             # dependency dependent\n",
    "    f'word{0}.head=' + word.head.orth_,                                      # dependency head\n",
    "    f'word{0}.isupper={word.orth_.isupper()}',                               # is the word in all uppercase\n",
    "    f'word{0}.isdigit={word.orth_.isdigit()}',                               # is the word a number\n",
    "    f'word{0}.startsWithCapital={word.orth_[0].isupper()}']                  # is the word starting with a capital letter\n",
    "\n",
    "        \n",
    "    if(cur_loc > 0):\n",
    "        word = sentence[cur_loc - 1]\n",
    "        features.extend([\n",
    "        f'word{-1}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "        f'word{-1}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "        f'word{-1}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "        f'word{-1}.dep=' + word.dep_,                                             # dependency dependent\n",
    "        f'word{-1}.head=' + word.head.orth_,                                      # dependency head\n",
    "        f'word{-1}.isupper={word.orth_.isupper()}',                               # is the word in all uppercase\n",
    "        f'word{-1}.isdigit={word.orth_.isdigit()}',                               # is the word a number\n",
    "        f'word{-1}.startsWithCapital={word.orth_[0].isupper()}'])                # is the word starting with a capital letter\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        features.append('BEG')                                          # feature to track begin of sentence \n",
    " \n",
    "    if(cur_loc + 1 < end_loc):\n",
    "        word = sentence[cur_loc + 1]\n",
    "        features.extend([\n",
    "        f'word{1}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "        f'word{1}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "        f'word{1}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "        f'word{1}.dep=' + word.dep_,                                             # dependency dependent\n",
    "        f'word{1}.head=' + word.head.orth_,                                      # dependency head\n",
    "        f'word{1}.isupper={word.orth_.isupper()}',                               # is the word in all uppercase\n",
    "        f'word{1}.isdigit={word.orth_.isdigit()}',                               # is the word a number\n",
    "        f'word{1}.startsWithCapital={word.orth_[0].isupper()}'])                  # is the word starting with a capital letter\n",
    "\n",
    "    else:\n",
    "        features.append('END')                                                # feature to track end of sentence\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab5a3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Previous and current word features\n",
    "def getFeaturesForOneWord(cur_loc, sentence):\n",
    "    end_loc = len(sentence) - 1\n",
    "    # Obtaining features for current word\n",
    "    word = sentence[cur_loc]\n",
    "\n",
    "    features = [\n",
    "    f'word{0}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "    f'word{0}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "    f'word{0}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "    f'word{0}.dep=' + word.dep_,                                             # dependency dependent\n",
    "    f'word{0}.head=' + word.head.orth_,                                      # dependency head\n",
    "    f'word{0}.isupper={word.orth_.isupper()}',                               # is the word in all uppercase\n",
    "    f'word{0}.isdigit={word.orth_.isdigit()}',                               # is the word a number\n",
    "    f'word{0}.startsWithCapital={word.orth_[0].isupper()}']                  # is the word starting with a capital letter\n",
    "\n",
    "        \n",
    "    if(cur_loc > 0):\n",
    "        word = sentence[cur_loc - 1]\n",
    "        features.extend([\n",
    "        f'word{-1}.lower=' + word.orth_.lower(),                                  # serves as word id\n",
    "        f'word{-1}.postag=' + word.pos_,                                          # PoS tag of current word\n",
    "        f'word{-1}[-3:]=' + word.orth_[-3:],                                      # last three characters\n",
    "        f'word{-1}.dep=' + word.dep_,                                             # dependency dependent\n",
    "        f'word{-1}.head=' + word.head.orth_,                                      # dependency head\n",
    "        f'word{-1}.isupper={word.orth_.isupper()}',                               # is the word in all uppercase\n",
    "        f'word{-1}.isdigit={word.orth_.isdigit()}',                               # is the word a number\n",
    "        f'word{-1}.startsWithCapital={word.orth_[0].isupper()}'])                # is the word starting with a capital letter\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        features.append('BEG')                                                # feature to track begin of sentence \n",
    "\n",
    "    if(cur_loc == end_loc):\n",
    "        features.append('END')                                                # feature to track end of sentence\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2df44f",
   "metadata": {},
   "source": [
    "# Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfcee6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for a sentence.\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "    sentence_parsing = model(sentence)\n",
    "    return [getFeaturesForOneWord(ii, sentence_parsing) for ii,token in enumerate(sentence_parsing)]\n",
    "\n",
    "# code to get the labels for a sentence.\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "    return labels.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ac43ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O O T O O O O O O D O D O O O O O O O O O'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aacbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: \"CONCLUSION : Methylphenidate is effective in treating children with epilepsy and ADHD and safe in children who are seizure free .\"\n",
      "\n",
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "Total features in the sentence: 21\n",
      "Example of features for the word \"rates\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['word-2.lower=conclusion',\n",
       " 'word-2.postag=NOUN',\n",
       " 'word-2[-3:]=ION',\n",
       " 'word-2.dep=dep',\n",
       " 'word-2.head=is',\n",
       " 'word-2.isupper=True',\n",
       " 'word-2.isdigit=False',\n",
       " 'word-2.startsWithCapital=True',\n",
       " 'word-1.lower=:',\n",
       " 'word-1.postag=PUNCT',\n",
       " 'word-1[-3:]=:',\n",
       " 'word-1.dep=punct',\n",
       " 'word-1.head=CONCLUSION',\n",
       " 'word-1.isupper=False',\n",
       " 'word-1.isdigit=False',\n",
       " 'word-1.startsWithCapital=False',\n",
       " 'word0.lower=methylphenidate',\n",
       " 'word0.postag=NOUN',\n",
       " 'word0[-3:]=ate',\n",
       " 'word0.dep=nsubj',\n",
       " 'word0.head=is',\n",
       " 'word0.isupper=False',\n",
       " 'word0.isdigit=False',\n",
       " 'word0.startsWithCapital=True',\n",
       " 'word1.lower=is',\n",
       " 'word1.postag=AUX',\n",
       " 'word1[-3:]=is',\n",
       " 'word1.dep=ROOT',\n",
       " 'word1.head=is',\n",
       " 'word1.isupper=False',\n",
       " 'word1.isdigit=False',\n",
       " 'word1.startsWithCapital=False',\n",
       " 'word2.lower=effective',\n",
       " 'word2.postag=ADJ',\n",
       " 'word2[-3:]=ive',\n",
       " 'word2.dep=acomp',\n",
       " 'word2.head=is',\n",
       " 'word2.isupper=False',\n",
       " 'word2.isdigit=False',\n",
       " 'word2.startsWithCapital=False',\n",
       " 'word3.lower=in',\n",
       " 'word3.postag=ADP',\n",
       " 'word3[-3:]=in',\n",
       " 'word3.dep=prep',\n",
       " 'word3.head=effective',\n",
       " 'word3.isupper=False',\n",
       " 'word3.isdigit=False',\n",
       " 'word3.startsWithCapital=False',\n",
       " 'word4.lower=treating',\n",
       " 'word4.postag=VERB',\n",
       " 'word4[-3:]=ing',\n",
       " 'word4.dep=pcomp',\n",
       " 'word4.head=in',\n",
       " 'word4.isupper=False',\n",
       " 'word4.isdigit=False',\n",
       " 'word4.startsWithCapital=False',\n",
       " 'word5.lower=children',\n",
       " 'word5.postag=NOUN',\n",
       " 'word5[-3:]=ren',\n",
       " 'word5.dep=dobj',\n",
       " 'word5.head=treating',\n",
       " 'word5.isupper=False',\n",
       " 'word5.isdigit=False',\n",
       " 'word5.startsWithCapital=False',\n",
       " 'word6.lower=with',\n",
       " 'word6.postag=ADP',\n",
       " 'word6[-3:]=ith',\n",
       " 'word6.dep=prep',\n",
       " 'word6.head=treating',\n",
       " 'word6.isupper=False',\n",
       " 'word6.isdigit=False',\n",
       " 'word6.startsWithCapital=False',\n",
       " 'word7.lower=epilepsy',\n",
       " 'word7.postag=NOUN',\n",
       " 'word7[-3:]=psy',\n",
       " 'word7.dep=pobj',\n",
       " 'word7.head=with',\n",
       " 'word7.isupper=False',\n",
       " 'word7.isdigit=False',\n",
       " 'word7.startsWithCapital=False',\n",
       " 'word8.lower=and',\n",
       " 'word8.postag=CCONJ',\n",
       " 'word8[-3:]=and',\n",
       " 'word8.dep=cc',\n",
       " 'word8.head=epilepsy',\n",
       " 'word8.isupper=False',\n",
       " 'word8.isdigit=False',\n",
       " 'word8.startsWithCapital=False',\n",
       " 'word9.lower=adhd',\n",
       " 'word9.postag=PROPN',\n",
       " 'word9[-3:]=DHD',\n",
       " 'word9.dep=conj',\n",
       " 'word9.head=epilepsy',\n",
       " 'word9.isupper=True',\n",
       " 'word9.isdigit=False',\n",
       " 'word9.startsWithCapital=True']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking feature extraction\n",
    "example_sentence = train_sentences[1]\n",
    "print(f'Example sentence: \"{example_sentence}\"\\n')\n",
    "\n",
    "features = getFeaturesForOneSentence(example_sentence)\n",
    "print('Total features in the sentence:', len(features))\n",
    "print('Example of features for the word \"rates\":')\n",
    "features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1e0c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-2.lower=conclusion\n",
      "word-2.postag=NOUN\n",
      "word-2[-3:]=ION\n",
      "word-2.dep=dep\n",
      "word-2.head=is\n",
      "word-2.isupper=True\n",
      "word-2.isdigit=False\n",
      "word-2.startsWithCapital=True\n",
      "word-1.lower=:\n",
      "word-1.postag=PUNCT\n",
      "word-1[-3:]=:\n",
      "word-1.dep=punct\n",
      "word-1.head=CONCLUSION\n",
      "word-1.isupper=False\n",
      "word-1.isdigit=False\n",
      "word-1.startsWithCapital=False\n",
      "word0.lower=methylphenidate\n",
      "word0.postag=NOUN\n",
      "word0[-3:]=ate\n",
      "word0.dep=nsubj\n",
      "word0.head=is\n",
      "word0.isupper=False\n",
      "word0.isdigit=False\n",
      "word0.startsWithCapital=True\n",
      "word1.lower=is\n",
      "word1.postag=AUX\n",
      "word1[-3:]=is\n",
      "word1.dep=ROOT\n",
      "word1.head=is\n",
      "word1.isupper=False\n",
      "word1.isdigit=False\n",
      "word1.startsWithCapital=False\n",
      "word2.lower=effective\n",
      "word2.postag=ADJ\n",
      "word2[-3:]=ive\n",
      "word2.dep=acomp\n",
      "word2.head=is\n",
      "word2.isupper=False\n",
      "word2.isdigit=False\n",
      "word2.startsWithCapital=False\n",
      "word3.lower=in\n",
      "word3.postag=ADP\n",
      "word3[-3:]=in\n",
      "word3.dep=prep\n",
      "word3.head=effective\n",
      "word3.isupper=False\n",
      "word3.isdigit=False\n",
      "word3.startsWithCapital=False\n",
      "word4.lower=treating\n",
      "word4.postag=VERB\n",
      "word4[-3:]=ing\n",
      "word4.dep=pcomp\n",
      "word4.head=in\n",
      "word4.isupper=False\n",
      "word4.isdigit=False\n",
      "word4.startsWithCapital=False\n",
      "word5.lower=children\n",
      "word5.postag=NOUN\n",
      "word5[-3:]=ren\n",
      "word5.dep=dobj\n",
      "word5.head=treating\n",
      "word5.isupper=False\n",
      "word5.isdigit=False\n",
      "word5.startsWithCapital=False\n",
      "word6.lower=with\n",
      "word6.postag=ADP\n",
      "word6[-3:]=ith\n",
      "word6.dep=prep\n",
      "word6.head=treating\n",
      "word6.isupper=False\n",
      "word6.isdigit=False\n",
      "word6.startsWithCapital=False\n",
      "word7.lower=epilepsy\n",
      "word7.postag=NOUN\n",
      "word7[-3:]=psy\n",
      "word7.dep=pobj\n",
      "word7.head=with\n",
      "word7.isupper=False\n",
      "word7.isdigit=False\n",
      "word7.startsWithCapital=False\n",
      "word8.lower=and\n",
      "word8.postag=CCONJ\n",
      "word8[-3:]=and\n",
      "word8.dep=cc\n",
      "word8.head=epilepsy\n",
      "word8.isupper=False\n",
      "word8.isdigit=False\n",
      "word8.startsWithCapital=False\n",
      "word9.lower=adhd\n",
      "word9.postag=PROPN\n",
      "word9[-3:]=DHD\n",
      "word9.dep=conj\n",
      "word9.head=epilepsy\n",
      "word9.isupper=True\n",
      "word9.isdigit=False\n",
      "word9.startsWithCapital=True\n"
     ]
    }
   ],
   "source": [
    "p = ''\n",
    "for i in zip(features[2], train_labels[1]):\n",
    "    p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "192042f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]\n",
    "\n",
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bca522",
   "metadata": {},
   "source": [
    "# build the CRF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62a0bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(max_iterations=300)\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, Y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "    \n",
    "predictions = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bffc4d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c4ea4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dba6d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using oprtion (1) - \"Range of SENT_RANGE word features\":\n",
      "Weighted F1: 0.9222604008175131\n",
      "Macro F1: 0.7947574532912421\n"
     ]
    }
   ],
   "source": [
    "print('Using oprtion (1) - \"Range of SENT_RANGE word features\":')\n",
    "print(\"Weighted F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='weighted')))\n",
    "print(\"Macro F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dceee82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using oprtion (2) - \"Previous, current and next word features\":\n",
      "Weighted F1: 0.9138709791733991\n",
      "Macro F1: 0.7690004082496799\n"
     ]
    }
   ],
   "source": [
    "print('Using oprtion (2) - \"Previous, current and next word features\":')\n",
    "print(\"Weighted F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='weighted')))\n",
    "print(\"Macro F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baab7205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using oprtion (3) - \"Previous and current word features\":\n",
      "Weighted F1: 0.9051708510330074\n",
      "Macro F1: 0.7440366657060755\n"
     ]
    }
   ],
   "source": [
    "print('Using oprtion (3) - \"Previous and current word features\":')\n",
    "print(\"Weighted F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='weighted')))\n",
    "print(\"Macro F1: {}\".format(metrics.flat_f1_score(Y_test, Y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b3096",
   "metadata": {},
   "source": [
    "# Extract all relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4430e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = train_sentences + test_sentences\n",
    "all_sentences_string = train_sentences + test_sentences\n",
    "all_sentences = [i.split() for i in all_sentences]\n",
    "all_labels = train_labels + test_labels\n",
    "all_labels = [i.split() for i in all_labels]\n",
    "condition_treatment_evidence = {'condition':[], 'treatment':[], 'evidence':[]}            # Initializing an empty dictionary\n",
    "\n",
    "\n",
    "for i in range(len(all_labels)):\n",
    "\n",
    "\n",
    "        #print(test_sentences[i])\n",
    "        cnt_disease = 0           # Count of number of diseases mentioned in the sentence\n",
    "        cnt_treatment = 0         # Count of the number of treatments mentioned in the sentence\n",
    "        diseases = [\"\"]           # Initializing a blank list of diseases for current sentence.\n",
    "        treatment = [\"\"]          # Initializing a blank list of treatments for current sentence.\n",
    "        sentence_number = [\"\"]\n",
    "        evidence = [\"\"]\n",
    "        \n",
    "        length = len(all_labels[i])   # Length of current sentence.\n",
    "        for j in range(length):\n",
    "            if (all_labels[i][j] == 'D'):                                                     # Checking for label indicating disease for current word ('D')\n",
    "                diseases[cnt_disease] += (all_sentences[i][j] + \" \")            # Adding word to diseases list.\n",
    "                if j < length - 1:\n",
    "                    if (all_labels[i][j+1] != 'D'):                                           # Check for name of disease extending over multiple words. \n",
    "                        # If next word does not have label 'D', then truncate the space added at the end of the last word.\n",
    "                        diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                        cnt_disease += 1\n",
    "                        diseases.append(\"\")                                               # Adding a placeholder for the next disease in the current sentence.\n",
    "                else:\n",
    "                    diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                    cnt_disease += 1\n",
    "                    diseases.append(\"\")\n",
    "                                \n",
    "            if (all_labels[i][j] == 'T'):                                                     # Checking for label indicating treatment for current word ('T')\n",
    "                treatment[cnt_treatment] += (all_sentences[i][j] + \" \") # Adding word to corresponding treatment list.\n",
    "                if j < length - 1:\n",
    "                    if (all_labels[i][j+1] != 'T'):                                           # Check for name of treatment extending over multiple words. \n",
    "                        # If next word does not have label 'T', then truncate the space added at the end of the last word.\n",
    "                        treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                        cnt_treatment += 1\n",
    "                        treatment.append(\"\")                                              # Adding a placeholder for the next treatment in the current sentence.\n",
    "                else:\n",
    "                    treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                    cnt_treatment += 1\n",
    "                    treatment.append(\"\")\n",
    "\n",
    "        diseases.pop(-1)    # Getting rid of the last empty placeholder in diseases list\n",
    "        treatment.pop(-1)   # Getting rid of the last empty placeholder in treatments list\n",
    "        if cnt_disease and cnt_treatment:\n",
    "            for i_deases in range(cnt_disease):\n",
    "                for j in range(cnt_treatment):             \n",
    "                    condition_treatment_evidence['condition'].append(diseases[i_deases])            \n",
    "                    condition_treatment_evidence['treatment'].append(treatment[j])\n",
    "                    condition_treatment_evidence['evidence'].append(all_sentences_string[i])\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(condition_treatment_evidence)\n",
    "  \n",
    "# # save a .json file\n",
    "df.to_json(r'relation2.jsonl',orient = 'records', lines = 'True')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed652063",
   "metadata": {},
   "source": [
    "# Train on all the data for prediction on new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "49ae177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time(minutes):  9.956\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "all_sentences = train_sentences + test_sentences\n",
    "all_labels = train_labels + test_labels\n",
    "all_sentences_f = [getFeaturesForOneSentence(sentence) for sentence in all_sentences]\n",
    "predictions = crf.predict(all_sentences_f)\n",
    "toc = time()\n",
    "\n",
    "print('Process time(minutes): ',round(((toc - tic)/60), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7c01f",
   "metadata": {},
   "source": [
    "# Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d38c2ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>treatment</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advanced renal cell carcinoma</td>\n",
       "      <td>various interferon alpha preparations</td>\n",
       "      <td>Studies with various interferon alpha preparat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced renal cell carcinoma</td>\n",
       "      <td>interferon alfa-n1 , interferon alfa-2a</td>\n",
       "      <td>Studies with various interferon alpha preparat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low-grade non-hodgkin 's lymphoma</td>\n",
       "      <td>interferon alpha</td>\n",
       "      <td>Recombinant and natural forms of interferon al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low-grade non-hodgkin 's lymphomas</td>\n",
       "      <td>interferon and various cytotoxic drugs</td>\n",
       "      <td>This approach is being extended to the clinic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>locally advanced squamous cell carcinoma of th...</td>\n",
       "      <td>docetaxel , cisplatin , fluorouracil ( 5-fu ) ...</td>\n",
       "      <td>PURPOSE : A phase I/II trial of docetaxel , ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>gangrenous and perforated appendicitis</td>\n",
       "      <td>imipenem/cilistatin</td>\n",
       "      <td>Ticarcillin/clavulanate versus imipenem/cilist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>acute coronary syndromes</td>\n",
       "      <td>antithrombotic therapy</td>\n",
       "      <td>Issues and challenges with antithrombotic ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>laser-thermal angioplasty</td>\n",
       "      <td>balloon angioplasty</td>\n",
       "      <td>Reduction of vasoreactivity and thrombogenicit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>epithelial ovarian cancer</td>\n",
       "      <td>high-dose chemotherapy with autologous stem-ce...</td>\n",
       "      <td>High-dose chemotherapy with autologous stem-ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>newly diagnosed or responsive multiple myeloma</td>\n",
       "      <td>chemoradiotherapy with autologous stem-cell su...</td>\n",
       "      <td>`` Tandem '' high-dose chemoradiotherapy with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            condition  \\\n",
       "0                       advanced renal cell carcinoma   \n",
       "1                       advanced renal cell carcinoma   \n",
       "2                   low-grade non-hodgkin 's lymphoma   \n",
       "3                  low-grade non-hodgkin 's lymphomas   \n",
       "4   locally advanced squamous cell carcinoma of th...   \n",
       "..                                                ...   \n",
       "83             gangrenous and perforated appendicitis   \n",
       "84                           acute coronary syndromes   \n",
       "85                          laser-thermal angioplasty   \n",
       "86                          epithelial ovarian cancer   \n",
       "87     newly diagnosed or responsive multiple myeloma   \n",
       "\n",
       "                                            treatment  \\\n",
       "0               various interferon alpha preparations   \n",
       "1             interferon alfa-n1 , interferon alfa-2a   \n",
       "2                                    interferon alpha   \n",
       "3              interferon and various cytotoxic drugs   \n",
       "4   docetaxel , cisplatin , fluorouracil ( 5-fu ) ...   \n",
       "..                                                ...   \n",
       "83                                imipenem/cilistatin   \n",
       "84                             antithrombotic therapy   \n",
       "85                                balloon angioplasty   \n",
       "86  high-dose chemotherapy with autologous stem-ce...   \n",
       "87  chemoradiotherapy with autologous stem-cell su...   \n",
       "\n",
       "                                             evidence  \n",
       "0   Studies with various interferon alpha preparat...  \n",
       "1   Studies with various interferon alpha preparat...  \n",
       "2   Recombinant and natural forms of interferon al...  \n",
       "3   This approach is being extended to the clinic ...  \n",
       "4   PURPOSE : A phase I/II trial of docetaxel , ci...  \n",
       "..                                                ...  \n",
       "83  Ticarcillin/clavulanate versus imipenem/cilist...  \n",
       "84  Issues and challenges with antithrombotic ther...  \n",
       "85  Reduction of vasoreactivity and thrombogenicit...  \n",
       "86  High-dose chemotherapy with autologous stem-ce...  \n",
       "87  `` Tandem '' high-dose chemoradiotherapy with ...  \n",
       "\n",
       "[88 rows x 3 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_treatment_evidence = {'condition':[], 'treatment':[], 'evidence':[]}            # Initializing an empty dictionary\n",
    "\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "\n",
    "\n",
    "        #print(test_sentences[i])\n",
    "        cnt_disease = 0           # Count of number of diseases mentioned in the sentence\n",
    "        cnt_treatment = 0         # Count of the number of treatments mentioned in the sentence\n",
    "        diseases = [\"\"]           # Initializing a blank list of diseases for current sentence.\n",
    "        treatment = [\"\"]          # Initializing a blank list of treatments for current sentence.\n",
    "        sentence_number = [\"\"]\n",
    "        evidence = [\"\"]\n",
    "        \n",
    "        length = len(Y_pred[i])   # Length of current sentence.\n",
    "        for j in range(length):\n",
    "            if (Y_pred[i][j] == 'D'):                                                     # Checking for label indicating disease for current word ('D')\n",
    "                diseases[cnt_disease] += (X_test[i][j][0].split('=')[1] + \" \")            # Adding word to diseases list.\n",
    "                if j < length - 1:\n",
    "                    if (Y_pred[i][j+1] != 'D'):                                           # Check for name of disease extending over multiple words. \n",
    "                        # If next word does not have label 'D', then truncate the space added at the end of the last word.\n",
    "                        diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                        cnt_disease += 1\n",
    "                        diseases.append(\"\")                                               # Adding a placeholder for the next disease in the current sentence.\n",
    "                else:\n",
    "                    diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                    cnt_disease += 1\n",
    "                    diseases.append(\"\")\n",
    "                                \n",
    "            if (Y_pred[i][j] == 'T'):                                                     # Checking for label indicating treatment for current word ('T')\n",
    "                treatment[cnt_treatment] += (X_test[i][j][0].split('=')[1] + \" \") # Adding word to corresponding treatment list.\n",
    "                if j < length - 1:\n",
    "                    if (Y_pred[i][j+1] != 'T'):                                           # Check for name of treatment extending over multiple words. \n",
    "                        # If next word does not have label 'T', then truncate the space added at the end of the last word.\n",
    "                        treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                        cnt_treatment += 1\n",
    "                        treatment.append(\"\")                                              # Adding a placeholder for the next treatment in the current sentence.\n",
    "                else:\n",
    "                    treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                    cnt_treatment += 1\n",
    "                    treatment.append(\"\")\n",
    "\n",
    "        diseases.pop(-1)    # Getting rid of the last empty placeholder in diseases list\n",
    "        treatment.pop(-1)   # Getting rid of the last empty placeholder in treatments list\n",
    "        if cnt_disease and cnt_treatment:\n",
    "            for i_deases in range(cnt_disease):\n",
    "                for j in range(cnt_treatment):             \n",
    "                    condition_treatment_evidence['condition'].append(diseases[i_deases])            \n",
    "                    condition_treatment_evidence['treatment'].append(treatment[j])\n",
    "                    condition_treatment_evidence['evidence'].append(test_sentences[i])\n",
    "\n",
    "\n",
    "# cleaned_condition_treatment_evidence = {'condition':[], 'treatment':[], 'evidence':[]}\n",
    "# print('the number of detected medical pairs plus evidence is:', len(cleaned_condition_treatment_evidence['evidence']))\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(condition_treatment_evidence)\n",
    "  \n",
    "# print dataframe.\n",
    "df\n",
    "\n",
    "# save a .json file\n",
    "#df.to_json(r'/content/drive/MyDrive/REL_Medical/relation2.jsonl',orient = 'records', lines = 'True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485fed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a46da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a85d62",
   "metadata": {},
   "source": [
    "# Extracting the medical relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e595a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of test sentence with both T and D actual label is : 297\n"
     ]
    }
   ],
   "source": [
    "# determine the number of test sentence with T or D or both T and D label.\n",
    "num_sent_with_D_T = 0\n",
    "for i in range(len(Y_test)):\n",
    "\n",
    "  string = ''.join([str(item) for item in Y_test[i]])\n",
    "  num_T = string.count('T')\n",
    "  num_D = string.count('D')\n",
    "\n",
    "  if num_T >= 1 :\n",
    "    if num_D >= 1 :\n",
    "\n",
    "      num_sent_with_D_T = num_sent_with_D_T + 1\n",
    "      #print(i)\n",
    "\n",
    "print('the number of test sentence with both T and D actual label is :', num_sent_with_D_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a7200746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advanced renal cell carcinoma']\n",
      "29 ['advanced renal cell carcinoma'] advanced renal cell carcinoma\n",
      "the number of detected medical pairs plus evidence is: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>treatment</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [condition, treatment, evidence]\n",
       "Index: []"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_treatment_evidence = {'condition':[], 'treatment':[], 'evidence':[]}            # Initializing an empty dictionary\n",
    "\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "\n",
    "\n",
    "        #print(test_sentences[i])\n",
    "        cnt_disease = 0           # Count of number of diseases mentioned in the sentence\n",
    "        cnt_treatment = 0         # Count of the number of treatments mentioned in the sentence\n",
    "        diseases = [\"\"]           # Initializing a blank list of diseases for current sentence.\n",
    "        treatment = [\"\"]          # Initializing a blank list of treatments for current sentence.\n",
    "        sentence_number = [\"\"]\n",
    "        evidence = [\"\"]\n",
    "        \n",
    "        length = len(Y_pred[i])   # Length of current sentence.\n",
    "        for j in range(length):\n",
    "            if (Y_pred[i][j] == 'D'):                                                     # Checking for label indicating disease for current word ('D')\n",
    "                diseases[cnt_disease] += (X_test[i][j][0].split('=')[1] + \" \")            # Adding word to diseases list.\n",
    "                if j < length - 1:\n",
    "                    if (Y_pred[i][j+1] != 'D'):                                           # Check for name of disease extending over multiple words. \n",
    "                        # If next word does not have label 'D', then truncate the space added at the end of the last word.\n",
    "                        diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                        cnt_disease += 1\n",
    "                        diseases.append(\"\")                                               # Adding a placeholder for the next disease in the current sentence.\n",
    "                else:\n",
    "                    diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                    cnt_disease += 1\n",
    "                    diseases.append(\"\")\n",
    "                                \n",
    "            if (Y_pred[i][j] == 'T'):                                                     # Checking for label indicating treatment for current word ('T')\n",
    "                treatment[cnt_treatment] += (X_test[i][j][0].split('=')[1] + \" \") # Adding word to corresponding treatment list.\n",
    "                if j < length - 1:\n",
    "                    if (Y_pred[i][j+1] != 'T'):                                           # Check for name of treatment extending over multiple words. \n",
    "                        # If next word does not have label 'T', then truncate the space added at the end of the last word.\n",
    "                        treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                        cnt_treatment += 1\n",
    "                        treatment.append(\"\")                                              # Adding a placeholder for the next treatment in the current sentence.\n",
    "                else:\n",
    "                    treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                    cnt_treatment += 1\n",
    "                    treatment.append(\"\")\n",
    "\n",
    "        diseases.pop(-1)    # Getting rid of the last empty placeholder in diseases list\n",
    "        treatment.pop(-1)   # Getting rid of the last empty placeholder in treatments list\n",
    "        condition_treatment_evidence['condition'].append(diseases)\n",
    "        condition_treatment_evidence['treatment'].append(treatment)\n",
    "        condition_treatment_evidence['evidence'].append(test_sentences[i])\n",
    "\n",
    "\n",
    "cleaned_condition_treatment_evidence = {'condition':[], 'treatment':[], 'evidence':[]}\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    conditions = condition_treatment_evidence['condition'][i]\n",
    "    treatments = condition_treatment_evidence['treatment'][i]\n",
    "    evidence = condition_treatment_evidence['evidence'][i]\n",
    "    both_list_ind = False\n",
    "    single_value_list_ind = False\n",
    "\n",
    "    if conditions != [] and treatments != []:\n",
    "        if 1 < len(treatments[0]) and 1 == len(conditions[0]):\n",
    "            list1 = treatments\n",
    "            list_name = 'treatment'\n",
    "            value = conditions\n",
    "            value_name = 'condition' \n",
    "        elif 1 < len(conditions[0]) and 1 == len(treatments[0]):\n",
    "            list1 = conditions\n",
    "            list_name = 'condition' \n",
    "            value = treatments\n",
    "            value_name = 'treatment'\n",
    "\n",
    "        elif 1 == len(conditions[0]) and 1 == len(treatments[0]):\n",
    "            single_value_list_ind = True\n",
    "        else:\n",
    "            both_list_ind = True\n",
    "\n",
    "        if both_list_ind:\n",
    "            print(conditions)\n",
    "            print(len(conditions[0]),conditions,conditions[0])\n",
    "            break\n",
    "        elif single_value_list_ind:\n",
    "              cleaned_condition_treatment_evidence['condition'].append(conditions)\n",
    "              cleaned_condition_treatment_evidence['treatment'].append(treatments)\n",
    "              cleaned_condition_treatment_evidence['evidence'].append(evidence)            \n",
    "        else:\n",
    "            for list_val in list1:\n",
    "              cleaned_condition_treatment_evidence[list_name].append(list_val)\n",
    "              cleaned_condition_treatment_evidence[value_name].append(value)\n",
    "              cleaned_condition_treatment_evidence['evidence'].append(evidence)\n",
    "\n",
    "print('the number of detected medical pairs plus evidence is:', len(cleaned_condition_treatment_evidence['evidence']))\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_condition_treatment_evidence)\n",
    "  \n",
    "# print dataframe.\n",
    "df\n",
    "\n",
    "# save a .json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01d1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bf4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4c4f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_treatment = {}            # Initializing an empty dictionary\n",
    "numsent_evidence = {}             # Initializing an empty dictionary\n",
    "for i in range(len(Y_pred)):\n",
    "    #print(test_sentences[i])\n",
    "    cnt_disease = 0           # Count of number of diseases mentioned in the sentence\n",
    "    cnt_treatment = 0         # Count of the number of treatments mentioned in the sentence\n",
    "    diseases = [\"\"]           # Initializing a blank list of diseases for current sentence.\n",
    "    treatment = [\"\"]          # Initializing a blank list of treatments for current sentence.\n",
    "    sentence_number = [\"\"]\n",
    "    evidence = [\"\"]\n",
    "    \n",
    "    length = len(Y_pred[i])   # Length of current sentence.\n",
    "    for j in range(length):\n",
    "        if (Y_pred[i][j] == 'D'):                                                     # Checking for label indicating disease for current word ('D')\n",
    "            diseases[cnt_disease] += (X_test[i][j][0].split('=')[1] + \" \")            # Adding word to diseases list.\n",
    "            if j < length - 1:\n",
    "                if (Y_pred[i][j+1] != 'D'):                                           # Check for name of disease extending over multiple words. \n",
    "                    # If next word does not have label 'D', then truncate the space added at the end of the last word.\n",
    "                    diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                    cnt_disease += 1\n",
    "                    diseases.append(\"\")                                               # Adding a placeholder for the next disease in the current sentence.\n",
    "            else:\n",
    "                diseases[cnt_disease] = diseases[cnt_disease][:-1]\n",
    "                cnt_disease += 1\n",
    "                diseases.append(\"\")\n",
    "                            \n",
    "        if (Y_pred[i][j] == 'T'):                                                     # Checking for label indicating treatment for current word ('T')\n",
    "            treatment[cnt_treatment] += (X_test[i][j][0].split('=')[1] + \" \") # Adding word to corresponding treatment list.\n",
    "            if j < length - 1:\n",
    "                if (Y_pred[i][j+1] != 'T'):                                           # Check for name of treatment extending over multiple words. \n",
    "                    # If next word does not have label 'T', then truncate the space added at the end of the last word.\n",
    "                    treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                    cnt_treatment += 1\n",
    "                    treatment.append(\"\")                                              # Adding a placeholder for the next treatment in the current sentence.\n",
    "            else:\n",
    "                treatment[cnt_treatment] = treatment[cnt_treatment][:-1]\n",
    "                cnt_treatment += 1\n",
    "                treatment.append(\"\")\n",
    "\n",
    "    diseases.pop(-1)    # Getting rid of the last empty placeholder in diseases list\n",
    "    treatment.pop(-1)   # Getting rid of the last empty placeholder in treatments list\n",
    "\n",
    "    # To our dictionary, add or append treatments to the diseases identified from the current sentence, if any.\n",
    "    if len(diseases) > 0:       # Checking if any diseases have been identified for the current sentence.\n",
    "\n",
    "        sentence_number = i\n",
    "        evidence = test_sentences[i]   \n",
    "        numsent_evidence[sentence_number] = evidence\n",
    "        for disease in diseases:\n",
    "            if disease in disease_treatment.keys():\n",
    "                # Extend treatment list if other treatments for the particular disease already exist\n",
    "                disease_treatment[disease].extend(treatment)\n",
    "            else:\n",
    "                # Creating list of treatments for particular disease if it doesn not exist already.\n",
    "                disease_treatment[disease] = treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining a cleaned version of our \"disease_treatment\" dictionary\n",
    "\n",
    "cleaned_dict = {\"sentence_number_in_test_set\" : [], \"disease\" : [], \"treatment\" : [], \"evidence\" : []}\n",
    "for sentence_number, disease in zip(numsent_evidence.keys(),disease_treatment.keys()):\n",
    "    if disease_treatment[disease] != []:\n",
    "        treatments = disease_treatment[disease]\n",
    "        if 1 < len(treatments[0]):\n",
    "            for treatment in treatments:\n",
    "                cleaned_dict[\"sentence_number_in_test_set\"].append(sentence_number)\n",
    "                cleaned_dict[\"disease\"].append(disease)\n",
    "                cleaned_dict[\"treatment\"].append(treatment)\n",
    "                cleaned_dict[\"evidence\"].append(numsent_evidence[sentence_number])\n",
    "        else:\n",
    "                cleaned_dict[\"sentence_number_in_test_set\"].append(sentence_number)\n",
    "                cleaned_dict[\"disease\"].append(disease)\n",
    "                cleaned_dict[\"treatment\"].append(treatments)\n",
    "                cleaned_dict[\"evidence\"].append(numsent_evidence[sentence_number])\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_dict)\n",
    "  \n",
    "# print dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d4066ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sentence_number_in_test_set'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e5bc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'disease':'condition'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f021810",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('relation22.jsonl', 'w')\n",
    "print(df.to_json(orient='records', lines=True), file=f, flush=False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8020ce01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>treatment</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macrosomic infants in gestational diabetes cases</td>\n",
       "      <td>good glycemic control</td>\n",
       "      <td>This study tested the hypothesis that to reduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancer</td>\n",
       "      <td>organ transplantation and chemotherapy</td>\n",
       "      <td>CONTEXT : A mutation in the BRCA1 gene may con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancer</td>\n",
       "      <td>oral drugs</td>\n",
       "      <td>CONTEXT : A mutation in the BRCA1 gene may con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancer</td>\n",
       "      <td>chemotherapy</td>\n",
       "      <td>CONTEXT : A mutation in the BRCA1 gene may con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cancer</td>\n",
       "      <td>matrix metalloproteinase inhibitors</td>\n",
       "      <td>CONTEXT : A mutation in the BRCA1 gene may con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>pertussis</td>\n",
       "      <td>vaccines</td>\n",
       "      <td>Thoracoscopy for empyema in children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>temporomandibular joint arthropathy</td>\n",
       "      <td>arthroscopic treatment</td>\n",
       "      <td>Conventional treatments for non-Hodgkin 's lym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>acute colonic pseudo-obstruction</td>\n",
       "      <td>neostigmine</td>\n",
       "      <td>Antiplatelet therapy in acute cerebral ischemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>severe secondary peritonitis</td>\n",
       "      <td>surgical management</td>\n",
       "      <td>Interferon treatment of renal cell carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>hepatic metastases from colorectal cancer</td>\n",
       "      <td>hepatic arterial infusion of chemotherapy afte...</td>\n",
       "      <td>Antimicrobial treatment options in the managem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              disease  \\\n",
       "0    macrosomic infants in gestational diabetes cases   \n",
       "1                                              cancer   \n",
       "2                                              cancer   \n",
       "3                                              cancer   \n",
       "4                                              cancer   \n",
       "..                                                ...   \n",
       "178                                         pertussis   \n",
       "179               temporomandibular joint arthropathy   \n",
       "180                  acute colonic pseudo-obstruction   \n",
       "181                      severe secondary peritonitis   \n",
       "182         hepatic metastases from colorectal cancer   \n",
       "\n",
       "                                             treatment  \\\n",
       "0                                good glycemic control   \n",
       "1               organ transplantation and chemotherapy   \n",
       "2                                           oral drugs   \n",
       "3                                         chemotherapy   \n",
       "4                  matrix metalloproteinase inhibitors   \n",
       "..                                                 ...   \n",
       "178                                           vaccines   \n",
       "179                             arthroscopic treatment   \n",
       "180                                        neostigmine   \n",
       "181                                surgical management   \n",
       "182  hepatic arterial infusion of chemotherapy afte...   \n",
       "\n",
       "                                              evidence  \n",
       "0    This study tested the hypothesis that to reduc...  \n",
       "1    CONTEXT : A mutation in the BRCA1 gene may con...  \n",
       "2    CONTEXT : A mutation in the BRCA1 gene may con...  \n",
       "3    CONTEXT : A mutation in the BRCA1 gene may con...  \n",
       "4    CONTEXT : A mutation in the BRCA1 gene may con...  \n",
       "..                                                 ...  \n",
       "178               Thoracoscopy for empyema in children  \n",
       "179  Conventional treatments for non-Hodgkin 's lym...  \n",
       "180    Antiplatelet therapy in acute cerebral ischemia  \n",
       "181       Interferon treatment of renal cell carcinoma  \n",
       "182  Antimicrobial treatment options in the managem...  \n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
